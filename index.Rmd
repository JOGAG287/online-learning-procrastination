---
title: "Exploratory analyses on procrastination data using cluster analysis"
output: 
  html_document:
    toc: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

<br>
<br>

# Cluster analysis

<br>

### Import data
```{r import_dat}
load("totscores_modif.Rda")
```


```{r import_lib}
library(cluster)
library(factoextra)
library(GGally)
library(tidyr)
library(plotly)
library(NbClust)
library(clValid)
library(dendextend)
library(purrr)
library(psych)
library(car)
library(fpc)
```
<br>

### Preparing data for cluster analysis
```{r data_prep}
# isolate clustering variables
clust_dat <- totscores_mod[ ,c(25:32)]

# Standardize the variables
scaled_dat <- scale(clust_dat)

# Compute the dissimilarity matrix
res.dist <- dist(scaled_dat, method = "euclidean")
dist_matrix <- as.matrix(res.dist)

```
<br>

### Compare estimation methods
```{r compare}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# function to compute coefficient
ac <- function(x) {
    agnes(scaled_dat, method = x)$ac
}

map_dbl(m, ac)
```

The analysis shows the superiority of the Ward method in this case.

<br>

### Determining the optimal number of clusters

```{r nb_clust}
res.nbclust <-
    NbClust(
        scaled_dat,
        distance = "euclidean",
        min.nc = 2,
        max.nc = 9,
        method = "complete",
        index = "all"
    )

factoextra::fviz_nbclust(res.nbclust) + 
    theme_minimal() + 
    ggtitle("NbClust's optimal number of clusters")
```


## Cluster analyses

<br>
<br>

### Kmeans
```{r kmeans}

# Computing Kmeans clustering
set.seed(124)
km.res <- kmeans(res.dist, 2, nstart = 1500)

# Visualizing kmeans clusters
fviz_cluster(
    km.res,
    data = res.dist,
    ellipse.type = "euclid",
    star.plot = T,
    repel = T,
    ggtheme = theme_minimal()
)
```
<br>

### K-Medoids
```{r kmedoids}

# PAM where nb. of cluster is specified
set.seed(101)
pam.res <- pam(dist_matrix, 2)

# Visualizing PAM clusters
fviz_cluster(
    pam.res,
    ellipse.type = "t",
    repel = T,
    ggtheme = theme_classic()
)

```
<br>

### Hierarchical Clustering
```{r agglo}

res.dist <- dist(scaled_dat, method = "euclidean")

# Create hierarchical tree
res.hc <- hclust(d = res.dist, method = "ward.D2")

fviz_dend(
    res.hc,
    k = 2,
    cex = .5,
    color_labels_by_k = T,
    rect = T)

# Cut the dendrogram into different groups
grp_hc <- cutree(res.hc, k = 2)

fviz_cluster(
    list(data = dist_matrix, cluster = grp_hc),
    ellipse.type = "convex",
    repel = T,
    show.clust.cent = F,
    ggtheme = theme_minimal()
)

```
<br>

### Agglomerative Nesting
```{r agnes}

res.agnes <- agnes(
    x = dist_matrix,
    stand = T,
    method = "ward"
)

fviz_dend(res.agnes, cez = .6, k = 2)

# Cut the dendrogram into different groups
grp_agnes <- cutree(res.agnes, k = 2)

fviz_cluster(
    list(data = dist_matrix, cluster = grp_agnes),
    ellipse.type = "convex",
    repel = T,
    show.clust.cent = F,
    ggtheme = theme_minimal()
)

```
<br>

### Divisive Analysis Clustering
```{r diana}

res.diana <- diana(x = dist_matrix)

fviz_dend(res.diana, cex = .6, k = 2)

grp_res.diana <- cutree(res.diana, k = 2)

fviz_cluster(
    list(data = dist_matrix, cluster = grp_res.diana),
    ellipse.type = "convex",
    repel = T,
    show.clust.cent = F,
    ggtheme = theme_minimal())

# Create a group variable based on clustering

totscores_mod$cluster_res.diana <- grp_res.diana

# Save the variable 
save(totscores_mod, file = "totscores_w_cluster.Rda")
```
<br>

### Hierarchical K-Means Clustering
```{r hkmeans}

res.hk <- hkmeans(dist_matrix, 2)

# Visualize the hkmeans final clusters
fviz_cluster(
    res.hk,
    cex = .6,
    palette = "jco",
    repel = T,
    ggtheme = theme_classic()
)

# Visualize the tree
fviz_dend(res.hk, cex = 0.6, palette = "jco",
          rect = TRUE, rect_border = "jco", rect_fill = TRUE)

# Create a group variable based on clustering
grp_res.hk <- res.hk$cluster
totscores_mod$cluster_res.hk <- grp_res.hk

# Save the grouping variable
save(totscores_mod, file = "totscores_w_cluster.Rda")

```
<br>
<br>

# Exploratory comparisons between clusters 

<br>

### Import libraries

```{r library}
library(tidyverse)
library(ggplot2)
```
<br>

### Import data files with clustering variable
```{r import data}
load(file = "totscores_w_cluster.Rda")
```
<br>

### Create factor variables from cluster variables and "proc_ouvert" variable
```{r data wrangling}

totscores_mod <- totscores_mod %>% 
    mutate(cluster_res.hk = factor(cluster_res.hk,
                            labels = c("1", "2"))) %>% 
    mutate(cluster_res.diana = factor(cluster_res.diana,
                                      labels = c("1", "2"))) %>% 
    mutate(proc_ouv = factor(proc_ouvert,
                             labels = c("À diminué",
                                        "Demeuré le même",
                                        "Empiré beaucoup",
                                        "Empiré quelque peu")))
```
<br>
<br>

## Visualize differences based on clustering variable

```{r plot}

totscores_mod %>% 
    ggplot(aes(proc_ouv, fill = cluster_res.hk)) +
    geom_histogram(stat = "count", binwidth = .5, alpha = .5) +
    facet_wrap(~cluster_res.hk, ncol = 1) +
    theme(axis.text.x = element_text(angle = 90)) +
    theme_bw()

totscores_mod %>% 
    ggplot(aes(proc_ouv, fill = cluster_res.diana)) +
    geom_histogram(stat = "count", binwidth = .5, alpha = .5) +
    facet_wrap(~cluster_res.diana, ncol = 1) +
    theme(axis.text.x = element_text(angle = 90)) +
    theme_bw()

totscores_mod %>% 
    ggplot(aes(pps_tot, fill = cluster_res.hk)) +
    geom_histogram(binwidth = .5, alpha = .5) +
    facet_wrap(~cluster_res.hk, ncol = 1) +
    theme(axis.text.x = element_text(angle = 90)) + 
    theme_bw()

totscores_mod %>% 
    ggplot(aes(pps_tot, fill = cluster_res.diana)) +
    geom_histogram(binwidth = .5, alpha = .5) +
    facet_wrap(~cluster_res.diana, ncol = 1) +
    theme(axis.text.x = element_text(angle = 90)) + 
    theme_bw()
```
<br>
<br>

## Exploratory analyses : mean differences
<br>

### Import library
```{r import_lib3}
library(rstatix)
```


```{r mean_sd}

sum_stats <- totscores_mod %>% 
    group_by(cluster_res.hk) %>% 
    get_summary_stats(type = "mean_sd")

sum_stats %>% 
    select(-n) %>% 
    print(n = 24)
```

